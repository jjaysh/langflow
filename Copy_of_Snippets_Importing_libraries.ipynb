{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjaysh/langflow/blob/main/Copy_of_Snippets_Importing_libraries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDn_lVxg3Z2G"
      },
      "source": [
        "# Importing a library that is not in Colaboratory\n",
        "\n",
        "To import a library that's not in Colaboratory by default, you can use `!pip install` or `!apt-get install`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "LxxjUIry4436"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/cic_ids_2018.csv')\n",
        "# Reset 'print' to its original function within your current session:\n",
        "print = __builtins__.print\n",
        "\n",
        "# Now you can use 'print' as usual\n",
        "print(\"This should work now!\")\n",
        "print(df.shape)\n",
        "df.head()\n",
        "df.tail(5)\n",
        "\n"
      ],
      "metadata": {
        "id": "zrd3e2T945FM",
        "outputId": "cc90ae27-15f1-4108-fbc4-a6e36772ac2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This should work now!\n",
            "(246730, 74)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0  Dst Port  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
              "246725      246725     53745             11             1             1   \n",
              "246726      246726       443            238             2             0   \n",
              "246727      246727       443            110             2             0   \n",
              "246728      246728      1131              2             1             1   \n",
              "246729      246729      1164              3             1             1   \n",
              "\n",
              "        TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  \\\n",
              "246725                0              0.0                0                0   \n",
              "246726                0              0.0                0                0   \n",
              "246727                0              0.0                0                0   \n",
              "246728                0              0.0                0                0   \n",
              "246729                0              0.0                0                0   \n",
              "\n",
              "        Fwd Pkt Len Mean  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
              "246725               0.0  ...                20          0.0         0.0   \n",
              "246726               0.0  ...                20          0.0         0.0   \n",
              "246727               0.0  ...                20          0.0         0.0   \n",
              "246728               0.0  ...                24          0.0         0.0   \n",
              "246729               0.0  ...                24          0.0         0.0   \n",
              "\n",
              "        Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min  \\\n",
              "246725         0.0         0.0        0.0       0.0       0.0       0.0   \n",
              "246726         0.0         0.0        0.0       0.0       0.0       0.0   \n",
              "246727         0.0         0.0        0.0       0.0       0.0       0.0   \n",
              "246728         0.0         0.0        0.0       0.0       0.0       0.0   \n",
              "246729         0.0         0.0        0.0       0.0       0.0       0.0   \n",
              "\n",
              "                Label  \n",
              "246725  Infilteration  \n",
              "246726  Infilteration  \n",
              "246727  Infilteration  \n",
              "246728  Infilteration  \n",
              "246729  Infilteration  \n",
              "\n",
              "[5 rows x 74 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d631c23a-dca3-4867-8cbb-3dd9f976b16c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Dst Port</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Tot Fwd Pkts</th>\n",
              "      <th>Tot Bwd Pkts</th>\n",
              "      <th>TotLen Fwd Pkts</th>\n",
              "      <th>TotLen Bwd Pkts</th>\n",
              "      <th>Fwd Pkt Len Max</th>\n",
              "      <th>Fwd Pkt Len Min</th>\n",
              "      <th>Fwd Pkt Len Mean</th>\n",
              "      <th>...</th>\n",
              "      <th>Fwd Seg Size Min</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>246725</th>\n",
              "      <td>246725</td>\n",
              "      <td>53745</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Infilteration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246726</th>\n",
              "      <td>246726</td>\n",
              "      <td>443</td>\n",
              "      <td>238</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Infilteration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246727</th>\n",
              "      <td>246727</td>\n",
              "      <td>443</td>\n",
              "      <td>110</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Infilteration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246728</th>\n",
              "      <td>246728</td>\n",
              "      <td>1131</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Infilteration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246729</th>\n",
              "      <td>246729</td>\n",
              "      <td>1164</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Infilteration</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 74 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d631c23a-dca3-4867-8cbb-3dd9f976b16c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d631c23a-dca3-4867-8cbb-3dd9f976b16c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d631c23a-dca3-4867-8cbb-3dd9f976b16c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ac5110fa-deb9-4b08-b035-b86579691f86\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac5110fa-deb9-4b08-b035-b86579691f86')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ac5110fa-deb9-4b08-b035-b86579691f86 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "id": "rRMjWqXz45OW",
        "outputId": "600c7461-d65e-4422-ef15-ed12646c5cd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(246730, 76)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "_-91dEGe45Ux",
        "outputId": "4be5def2-8963-486f-837f-ab2d5da90c16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0       0\n",
            "Dst Port         0\n",
            "Flow Duration    0\n",
            "Tot Fwd Pkts     0\n",
            "Tot Bwd Pkts     0\n",
            "                ..\n",
            "Idle Mean        0\n",
            "Idle Std         0\n",
            "Idle Max         0\n",
            "Idle Min         0\n",
            "Label            0\n",
            "Length: 74, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 246730 entries, 0 to 246729\n",
            "Data columns (total 74 columns):\n",
            " #   Column             Non-Null Count   Dtype  \n",
            "---  ------             --------------   -----  \n",
            " 0   Unnamed: 0         246730 non-null  int64  \n",
            " 1   Dst Port           246730 non-null  int64  \n",
            " 2   Flow Duration      246730 non-null  int64  \n",
            " 3   Tot Fwd Pkts       246730 non-null  int64  \n",
            " 4   Tot Bwd Pkts       246730 non-null  int64  \n",
            " 5   TotLen Fwd Pkts    246730 non-null  int64  \n",
            " 6   TotLen Bwd Pkts    246730 non-null  float64\n",
            " 7   Fwd Pkt Len Max    246730 non-null  int64  \n",
            " 8   Fwd Pkt Len Min    246730 non-null  int64  \n",
            " 9   Fwd Pkt Len Mean   246730 non-null  float64\n",
            " 10  Fwd Pkt Len Std    246730 non-null  float64\n",
            " 11  Bwd Pkt Len Max    246730 non-null  int64  \n",
            " 12  Bwd Pkt Len Min    246730 non-null  int64  \n",
            " 13  Bwd Pkt Len Mean   246730 non-null  float64\n",
            " 14  Bwd Pkt Len Std    246730 non-null  float64\n",
            " 15  Flow IAT Mean      246730 non-null  float64\n",
            " 16  Flow IAT Std       246730 non-null  float64\n",
            " 17  Flow IAT Max       246730 non-null  float64\n",
            " 18  Flow IAT Min       246730 non-null  float64\n",
            " 19  Fwd IAT Tot        246730 non-null  float64\n",
            " 20  Fwd IAT Mean       246730 non-null  float64\n",
            " 21  Fwd IAT Std        246730 non-null  float64\n",
            " 22  Fwd IAT Max        246730 non-null  float64\n",
            " 23  Fwd IAT Min        246730 non-null  float64\n",
            " 24  Bwd IAT Tot        246730 non-null  float64\n",
            " 25  Bwd IAT Mean       246730 non-null  float64\n",
            " 26  Bwd IAT Std        246730 non-null  float64\n",
            " 27  Bwd IAT Max        246730 non-null  float64\n",
            " 28  Bwd IAT Min        246730 non-null  float64\n",
            " 29  Fwd PSH Flags      246730 non-null  int64  \n",
            " 30  Bwd PSH Flags      246730 non-null  int64  \n",
            " 31  Fwd URG Flags      246730 non-null  int64  \n",
            " 32  Bwd URG Flags      246730 non-null  int64  \n",
            " 33  Fwd Header Len     246730 non-null  int64  \n",
            " 34  Bwd Header Len     246730 non-null  int64  \n",
            " 35  Fwd Pkts/s         246730 non-null  float64\n",
            " 36  Bwd Pkts/s         246730 non-null  float64\n",
            " 37  Pkt Len Min        246730 non-null  int64  \n",
            " 38  Pkt Len Max        246730 non-null  int64  \n",
            " 39  Pkt Len Mean       246730 non-null  float64\n",
            " 40  Pkt Len Std        246730 non-null  float64\n",
            " 41  Pkt Len Var        246730 non-null  float64\n",
            " 42  FIN Flag Cnt       246730 non-null  int64  \n",
            " 43  SYN Flag Cnt       246730 non-null  int64  \n",
            " 44  RST Flag Cnt       246730 non-null  int64  \n",
            " 45  ACK Flag Cnt       246730 non-null  int64  \n",
            " 46  URG Flag Cnt       246730 non-null  int64  \n",
            " 47  CWE Flag Count     246730 non-null  int64  \n",
            " 48  ECE Flag Cnt       246730 non-null  int64  \n",
            " 49  Pkt Size Avg       246730 non-null  float64\n",
            " 50  Fwd Seg Size Avg   246730 non-null  float64\n",
            " 51  Bwd Seg Size Avg   246730 non-null  float64\n",
            " 52  Fwd Byts/b Avg     246730 non-null  int64  \n",
            " 53  Fwd Pkts/b Avg     246730 non-null  int64  \n",
            " 54  Fwd Blk Rate Avg   246730 non-null  int64  \n",
            " 55  Bwd Byts/b Avg     246730 non-null  int64  \n",
            " 56  Bwd Pkts/b Avg     246730 non-null  int64  \n",
            " 57  Bwd Blk Rate Avg   246730 non-null  int64  \n",
            " 58  Subflow Fwd Pkts   246730 non-null  int64  \n",
            " 59  Subflow Fwd Byts   246730 non-null  int64  \n",
            " 60  Subflow Bwd Pkts   246730 non-null  int64  \n",
            " 61  Subflow Bwd Byts   246730 non-null  int64  \n",
            " 62  Init Bwd Win Byts  246730 non-null  int64  \n",
            " 63  Fwd Act Data Pkts  246730 non-null  int64  \n",
            " 64  Fwd Seg Size Min   246730 non-null  int64  \n",
            " 65  Active Mean        246730 non-null  float64\n",
            " 66  Active Std         246730 non-null  float64\n",
            " 67  Active Max         246730 non-null  float64\n",
            " 68  Active Min         246730 non-null  float64\n",
            " 69  Idle Mean          246730 non-null  float64\n",
            " 70  Idle Std           246730 non-null  float64\n",
            " 71  Idle Max           246730 non-null  float64\n",
            " 72  Idle Min           246730 non-null  float64\n",
            " 73  Label              246730 non-null  object \n",
            "dtypes: float64(35), int64(38), object(1)\n",
            "memory usage: 139.3+ MB\n",
            "None\n",
            "          Unnamed: 0       Dst Port  Flow Duration   Tot Fwd Pkts  \\\n",
            "count  246730.000000  246730.000000   2.467300e+05  246730.000000   \n",
            "mean   123364.500000    8074.691019   6.921339e+06     827.188327   \n",
            "std     71224.960296   17722.969247   1.372122e+09   10073.807988   \n",
            "min         0.000000       0.000000  -6.814020e+11       1.000000   \n",
            "25%     61682.250000      53.000000   2.200000e+02       1.000000   \n",
            "50%    123364.500000      80.000000   6.738000e+03       2.000000   \n",
            "75%    185046.750000    3389.000000   1.405900e+06       5.000000   \n",
            "max    246729.000000   65533.000000   1.200000e+08  309629.000000   \n",
            "\n",
            "        Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
            "count  246730.000000     2.467300e+05     2.467300e+05    246730.000000   \n",
            "mean        3.690204     2.670948e+04     1.542239e+03       198.037843   \n",
            "std        67.415180     3.223814e+05     9.600147e+04       309.627281   \n",
            "min         0.000000     0.000000e+00     0.000000e+00         0.000000   \n",
            "25%         0.000000     0.000000e+00     0.000000e+00         0.000000   \n",
            "50%         1.000000     3.000000e+01     0.000000e+00        29.000000   \n",
            "75%         3.000000     3.990000e+02     3.100000e+02       326.000000   \n",
            "max     24263.000000     9.908128e+06     3.489395e+07     10024.000000   \n",
            "\n",
            "       Fwd Pkt Len Min  Fwd Pkt Len Mean  ...  Fwd Act Data Pkts  \\\n",
            "count    246730.000000     246730.000000  ...      246730.000000   \n",
            "mean          5.935962         49.092340  ...         824.484295   \n",
            "std          19.602684         66.561973  ...       10073.911032   \n",
            "min           0.000000          0.000000  ...           0.000000   \n",
            "25%           0.000000          0.000000  ...           0.000000   \n",
            "50%           0.000000         10.333333  ...           0.000000   \n",
            "75%           0.000000         87.636364  ...           1.000000   \n",
            "max        1460.000000       2946.678571  ...      309628.000000   \n",
            "\n",
            "       Fwd Seg Size Min   Active Mean    Active Std    Active Max  \\\n",
            "count     246730.000000  2.467300e+05  2.467300e+05  2.467300e+05   \n",
            "mean          24.818757  2.001141e+05  7.863393e+04  2.695800e+05   \n",
            "std           10.032551  1.820645e+06  1.056338e+06  2.416334e+06   \n",
            "min            0.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "25%           20.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "50%           20.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "75%           32.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "max           40.000000  1.120000e+08  6.780000e+07  1.120000e+08   \n",
            "\n",
            "         Active Min     Idle Mean      Idle Std      Idle Max      Idle Min  \n",
            "count  2.467300e+05  2.467300e+05  2.467300e+05  2.467300e+05  2.467300e+05  \n",
            "mean   1.460819e+05  3.622192e+06  4.366032e+05  4.191420e+06  3.249840e+06  \n",
            "std    1.490780e+06  1.444862e+07  2.899844e+06  1.572425e+07  1.412678e+07  \n",
            "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
            "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
            "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
            "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
            "max    1.120000e+08  1.195160e+08  5.474350e+07  1.195160e+08  1.195160e+08  \n",
            "\n",
            "[8 rows x 73 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn numpy # Install scikit-learn and numpy if you haven't already\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'df' is your pandas DataFrame with shape (246730, 74)\n",
        "\n",
        "# Custom normalization function (handling NaNs and preserving rows)\n",
        "def normalize_column(column):\n",
        "    \"\"\"Normalizes a column to have unit norm (L2 norm),\n",
        "    handling NaNs and preserving rows.\"\"\"\n",
        "    # Calculate norm using only valid (non-NaN) values\n",
        "    valid_values = column[~np.isnan(column)]\n",
        "    norm = np.linalg.norm(valid_values)\n",
        "\n",
        "    # If norm is 0, avoid division by 0 and return original column\n",
        "    if norm == 0:\n",
        "        return column\n",
        "\n",
        "    # Normalize values, preserving NaNs\n",
        "    normalized_values = column.copy()  # Create a copy to avoid modifying the original\n",
        "    normalized_values[~np.isnan(column)] = normalized_values[~np.isnan(column)] / norm\n",
        "    return normalized_values\n",
        "\n",
        "# Columns to normalize\n",
        "columns_to_normalize_row = df.columns[:2]  # Example: Normalize the first two columns\n",
        "\n",
        "# Apply normalization to selected columns\n",
        "for col in columns_to_normalize_row:\n",
        "    df[f'{col}_normalized'] = normalize_column(df[col])\n",
        "\n",
        "# Check for data loss\n",
        "initial_rows = df.shape[0]\n",
        "rows_after_normalization = df.shape[0]\n",
        "data_loss = initial_rows - rows_after_normalization\n",
        "\n",
        "print(f\"Initial rows: {initial_rows}\")\n",
        "print(f\"Rows after normalization: {rows_after_normalization}\")\n",
        "print(f\"Data loss: {data_loss}\")\n",
        "\n",
        "# Verify normalization for each column\n",
        "for col in columns_to_normalize_row:\n",
        "    # Calculate norm of normalized column, ignoring NaNs\n",
        "    norm = np.linalg.norm(df[f'{col}_normalized'].dropna())\n",
        "    is_normalized = np.isclose(norm, 1, atol=1e-6)  # Allow small tolerance\n",
        "\n",
        "    if is_normalized:\n",
        "        print(f\"Data in column '{col}' has been normalized successfully.\")\n",
        "    else:\n",
        "        print(f\"Data in column '{col}' has not been normalized as expected.\")\n",
        "        print(\"Norm of the column:\", norm)"
      ],
      "metadata": {
        "id": "pqErEGGVVqvN",
        "outputId": "457936c4-f2b5-454a-9447-91c1a4bbe090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Initial rows: 246730\n",
            "Rows after normalization: 246730\n",
            "Data loss: 0\n",
            "Data in column 'Unnamed: 0' has been normalized successfully.\n",
            "Data in column 'Dst Port' has been normalized successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-75-d88d26b4ba19>:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.00000000e+00 1.41328259e-08 2.82656518e-08 ... 3.48694974e-03\n",
            " 3.48696387e-03 3.48697800e-03]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  normalized_values[~np.isnan(column)] = normalized_values[~np.isnan(column)] / norm\n",
            "<ipython-input-75-d88d26b4ba19>:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[3.50322031e-04 5.47862722e-06 0.00000000e+00 ... 4.57930539e-05\n",
            " 1.16911837e-04 1.20323058e-04]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  normalized_values[~np.isnan(column)] = normalized_values[~np.isnan(column)] / norm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_column(column):\n",
        "    \"\"\"Normalizes a column to have unit norm (L2 norm),\n",
        "    handling NaNs and preserving rows.\"\"\"\n",
        "    # Calculate norm using only valid (non-NaN) values\n",
        "    valid_values = column[~np.isnan(column)]\n",
        "    norm = np.linalg.norm(valid_values)\n",
        "\n",
        "    # If norm is 0, avoid division by 0 and return original column\n",
        "    if norm == 0:\n",
        "        return column\n",
        "\n",
        "    # Normalize values, preserving NaNs\n",
        "    normalized_values = column.copy()  # Create a copy to avoid modifying the original\n",
        "    normalized_values[~np.isnan(column)] = normalized_values[~np.isnan(column)] / norm\n",
        "\n",
        "    # Cast normalized values to original data type if it's integer\n",
        "    if column.dtype == np.int64:\n",
        "        normalized_values = normalized_values.astype(np.int64)\n",
        "\n",
        "    return normalized_values"
      ],
      "metadata": {
        "id": "0aZ_a2POVqya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn numpy pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ... (Your existing code for normalize_column function) ...\n",
        "\n",
        "# Columns to normalize (Explicitly include 'Unnamed: 0')\n",
        "columns_to_normalize_row = ['Unnamed: 0'] + list(df.columns[1:2])  # Include 'Unnamed: 0'\n",
        "\n",
        "# Apply normalization to selected columns\n",
        "for col in columns_to_normalize_row:\n",
        "    try:\n",
        "        df[f'{col}_normalized'] = normalize_column(df[col])\n",
        "    except (TypeError, ValueError) as e:\n",
        "        print(f\"Error normalizing column '{col}': {e}\")\n",
        "        # Handle the error, e.g., skip the column or fill with NaNs\n",
        "        # df[f'{col}_normalized'] = np.nan  # Example: Fill with NaNs\n",
        "\n",
        "# Check for unintended row deletions\n",
        "initial_rows = df.shape[0]\n",
        "\n",
        "# ... (Your existing verification code) ...\n",
        "\n",
        "# Recheck for unintended row deletions after verification loop\n",
        "final_rows = df.shape[0]\n",
        "if initial_rows != final_rows:\n",
        "    print(f\"Warning: Rows were deleted during processing. Initial: {initial_rows}, Final: {final_rows}\")"
      ],
      "metadata": {
        "id": "xgwGp7tRZmjb",
        "outputId": "aa1d45cc-f117-418f-8f1d-5ec09915c722",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-95-ad109d89e9ec>:14: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.00000000e+00 1.41328259e-08 2.82656518e-08 ... 3.48694974e-03\n",
            " 3.48696387e-03 3.48697800e-03]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  normalized_values[~np.isnan(column)] = normalized_values[~np.isnan(column)] / norm\n",
            "<ipython-input-95-ad109d89e9ec>:14: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[3.50322031e-04 5.47862722e-06 0.00000000e+00 ... 4.57930539e-05\n",
            " 1.16911837e-04 1.20323058e-04]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  normalized_values[~np.isnan(column)] = normalized_values[~np.isnan(column)] / norm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn numpy pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ... (Your normalize_column function remains the same) ...\n",
        "\n",
        "# Assuming 'df' is your pandas DataFrame\n",
        "# Columns to normalize (Explicitly include 'Unnamed: 0')\n",
        "columns_to_normalize_row = ['Unnamed: 0'] + list(df.columns[1:2])  # Include 'Unnamed: 0'\n",
        "\n",
        "# **Change 1: Cast original columns to float before normalization**\n",
        "for col in columns_to_normalize_row:\n",
        "    df[col] = df[col].astype(float)  # Cast to float here\n",
        "\n",
        "# Apply normalization to selected columns, handling errors\n",
        "for col in columns_to_normalize_row:\n",
        "    try:\n",
        "        df[f'{col}_normalized'] = normalize_column(df[col])\n",
        "    except (TypeError, ValueError, KeyError) as e:\n",
        "        print(f\"Error normalizing column '{col}': {e}\")\n",
        "        df[f'{col}_normalized'] = np.nan  # Example: Fill with NaNs\n",
        "\n",
        "# ... (Rest of your code remains the same) ..."
      ],
      "metadata": {
        "id": "dn-kYDA-Slny",
        "outputId": "915c220a-2861-4972-9e56-0a8ec6386056",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify normalization for each column\n",
        "for col in columns_to_normalize_row:\n",
        "    try:\n",
        "        norm = np.linalg.norm(df[f'{col}_normalized'].dropna())\n",
        "        is_normalized = np.isclose(norm, 1, atol=1e-6)\n",
        "        if is_normalized:\n",
        "            print(f\"Data in column '{col}' has been normalized successfully.\")\n",
        "        else:\n",
        "            print(f\"Data in column '{col}' has not been normalized as expected.\")\n",
        "            print(\"Norm of the column:\", norm)\n",
        "    except KeyError as e:\n",
        "        print(f\"Error verifying column '{col}': {e}\")"
      ],
      "metadata": {
        "id": "b9FSK8vncMEA",
        "outputId": "0065d05e-9ddd-40dc-bfcd-4d1f45fac55c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data in column 'Unnamed: 0' has been normalized successfully.\n",
            "Data in column 'Dst Port' has been normalized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "id": "oUj6tpO5cMhp",
        "outputId": "d540abfa-88bd-4afc-dd12-3eaa7db4c0a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'Dst Port', 'Flow Duration', 'Tot Fwd Pkts',\n",
            "       'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max',\n",
            "       'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std',\n",
            "       'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean',\n",
            "       'Bwd Pkt Len Std', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
            "       'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
            "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean',\n",
            "       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
            "       'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Len',\n",
            "       'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min',\n",
            "       'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var',\n",
            "       'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'ACK Flag Cnt',\n",
            "       'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Pkt Size Avg',\n",
            "       'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg',\n",
            "       'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg',\n",
            "       'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts',\n",
            "       'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts',\n",
            "       'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min',\n",
            "       'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
            "       'Idle Std', 'Idle Max', 'Idle Min', 'Label', 'Unnamed: 0_normalized',\n",
            "       'Dst Port_normalized'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Identify your target variable (label) column:\n",
        "target_column = 'Label'  # Replace with your actual target column name\n",
        "\n",
        "# 2. Check if the target column exists and handle the error if it doesn't\n",
        "if target_column in df.columns:\n",
        "    # 3. Define X (features) and y (labels):\n",
        "    X = df.drop(columns=[target_column])\n",
        "    y = df[target_column]\n",
        "\n",
        "    # 4. Split the data into training and testing sets (80/20 split)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Now you have:\n",
        "    # - X_train: 80% of your data for training (features)\n",
        "    # - X_test: 20% of your data for testing (features)\n",
        "    # - y_train: 80% of your data for training (labels)\n",
        "    # - y_test: 20% of your data for testing (labels)\n",
        "\n",
        "    print(\"Data split successfully:\")\n",
        "    print(f\"X_train shape: {X_train.shape}\")\n",
        "    print(f\"X_test shape: {X_test.shape}\")\n",
        "    print(f\"y_train shape: {y_train.shape}\")\n",
        "    print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Error: Target column '{target_column}' not found in the DataFrame.\")\n",
        "    # Handle the error as described in the previous response"
      ],
      "metadata": {
        "id": "5UvHMtNWcMlE",
        "outputId": "d132e239-ecee-4345-dd2b-074cd2e5ac11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Data split successfully:\n",
            "X_train shape: (197384, 75)\n",
            "X_test shape: (49346, 75)\n",
            "y_train shape: (197384,)\n",
            "y_test shape: (49346,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Check for Missing Values\n",
        "missing_train = np.isnan(X_train).sum()\n",
        "missing_test = np.isnan(X_test).sum()\n",
        "print(f\"Missing values in X_train: {missing_train}\")\n",
        "print(f\"Missing values in X_test: {missing_test}\")\n",
        "\n",
        "# Check for Normalization (StandardScaler - assuming it was used)\n",
        "train_mean = np.mean(X_train, axis=0)\n",
        "train_std = np.std(X_train, axis=0)\n",
        "print(f\"Mean of X_train features: {train_mean}\")\n",
        "print(f\"Standard deviation of X_train features: {train_std}\")\n",
        "\n",
        "# Check for Normalization (MinMaxScaler - assuming it was used)\n",
        "train_min = np.min(X_train)\n",
        "train_max = np.max(X_train)\n",
        "print(f\"Minimum value in X_train: {train_min}\")\n",
        "print(f\"Maximum value in X_train: {train_max}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfhLct_mgWPa",
        "outputId": "d6416a12-74aa-40bb-f0c4-d12b3c33bcfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in X_train: 0\n",
            "Missing values in X_test: 0\n",
            "Mean of X_train features: [ 5.43925306e-04  2.39526786e+00  4.42044757e+00  2.07482867e+02\n",
            "  9.03306921e-01  6.72297534e+01  5.10910964e+00  5.18404426e-01\n",
            "  5.89625299e+00  4.41450787e-01  5.69658034e-01  8.17240972e-01\n",
            "  1.27670683e+01  6.18534215e-01  5.57835162e-01  1.13826988e-01\n",
            "  7.95485026e+01  4.54686345e+00 -3.12694287e+03  1.43741792e+01\n",
            "  9.18645846e+00  1.01414426e+02  1.69944173e+01 -1.03913065e+03\n",
            "  1.77238402e+02  1.45863457e+02  1.92735516e+02  1.27411851e+02\n",
            "  4.72145582e+04  3.49015118e-02  0.00000000e+00  1.14497629e-03\n",
            "  0.00000000e+00  7.94241054e+01  7.57012594e-01  9.70739118e+00\n",
            "  2.46599486e+01  5.67692417e+00  4.22329011e-01  4.79757359e-01\n",
            "  4.67156151e-01  7.58990274e-01  2.87763952e-03  3.49015118e-02\n",
            "  1.59511409e-01  3.62293803e-01  5.40013375e-02  1.14497629e-03\n",
            "  1.59511409e-01  4.44639049e-01  4.41450790e-01  6.18534229e-01\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  2.07482867e+02  6.72297534e+01\n",
            "  9.03306921e-01  5.10910964e+00  2.05607649e+01  8.29205133e+02\n",
            "  4.01547238e-01  1.96475145e+05  7.66189180e+04  2.64631937e+05\n",
            "  1.43974902e+05  3.62997815e+06  4.33988291e+05  4.19536865e+06\n",
            "  3.25959760e+06  5.43925306e-04  2.39526786e+00]\n",
            "Standard deviation of X_train features: [5.77137624e-01 5.30914906e+00 1.09082929e+03 2.52784017e+03\n",
            " 2.38903410e+01 8.10952216e+02 3.29779474e+02 9.49987179e-01\n",
            " 1.93112096e+01 7.58583726e-01 9.36763165e-01 1.40404269e+00\n",
            " 3.77313627e+01 1.08597853e+00 9.91919628e-01 6.47958358e+03\n",
            " 1.62354912e+04 3.98146474e+02 2.16766966e+06 3.72640741e+03\n",
            " 7.63149433e+03 2.59156084e+04 1.55451097e+03 2.24222811e+06\n",
            " 6.43336921e+02 7.59110475e+02 8.51555305e+02 5.24391182e+02\n",
            " 3.24078311e+05 1.83530369e-01 0.00000000e+00 3.38181212e-02\n",
            " 0.00000000e+00 9.62943583e+02 1.56115554e+01 2.53960030e+01\n",
            " 6.09285431e+01 1.84469837e+01 6.89543766e-01 8.13090228e-01\n",
            " 7.21568521e-01 1.57947785e+00 5.35663954e-02 1.83530369e-01\n",
            " 3.66152317e-01 4.80663087e-01 2.26020338e-01 3.38181212e-02\n",
            " 3.66152317e-01 7.29019899e-01 7.58583725e-01 1.08597855e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 2.52784017e+03 8.10952216e+02\n",
            " 2.38903410e+01 3.29779474e+02 6.56097951e+01 1.01114579e+04\n",
            " 8.35637295e-01 1.78690604e+06 1.02778674e+06 2.36884322e+06\n",
            " 1.47073015e+06 1.44764118e+07 2.89102216e+06 1.57419513e+07\n",
            " 1.41568094e+07 5.77137624e-01 5.30914906e+00]\n",
            "Minimum value in X_train: -996114503.8969465\n",
            "Maximum value in X_train: 119516011.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Check for Missing Values\n",
        "missing_train = np.isnan(X_train).sum()\n",
        "missing_test = np.isnan(X_test).sum()\n",
        "print(f\"Missing values in X_train: {missing_train}\")\n",
        "print(f\"Missing values in X_test: {missing_test}\")\n",
        "\n",
        "# Check for Normalization (StandardScaler - assuming it was used)\n",
        "train_mean = np.mean(X_train, axis=0)\n",
        "train_std = np.std(X_train, axis=0)\n",
        "print(f\"Mean of X_train features: {train_mean}\")\n",
        "print(f\"Standard deviation of X_train features: {train_std}\")\n",
        "\n",
        "# Check for Normalization (MinMaxScaler - assuming it was used)\n",
        "train_min = np.min(X_train)\n",
        "train_max = np.max(X_train)\n",
        "print(f\"Minimum value in X_train: {train_min}\")\n",
        "print(f\"Maximum value in X_train: {train_max}\")"
      ],
      "metadata": {
        "outputId": "d6416a12-74aa-40bb-f0c4-d12b3c33bcfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZiX4I-LklJ_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in X_train: 0\n",
            "Missing values in X_test: 0\n",
            "Mean of X_train features: [ 5.43925306e-04  2.39526786e+00  4.42044757e+00  2.07482867e+02\n",
            "  9.03306921e-01  6.72297534e+01  5.10910964e+00  5.18404426e-01\n",
            "  5.89625299e+00  4.41450787e-01  5.69658034e-01  8.17240972e-01\n",
            "  1.27670683e+01  6.18534215e-01  5.57835162e-01  1.13826988e-01\n",
            "  7.95485026e+01  4.54686345e+00 -3.12694287e+03  1.43741792e+01\n",
            "  9.18645846e+00  1.01414426e+02  1.69944173e+01 -1.03913065e+03\n",
            "  1.77238402e+02  1.45863457e+02  1.92735516e+02  1.27411851e+02\n",
            "  4.72145582e+04  3.49015118e-02  0.00000000e+00  1.14497629e-03\n",
            "  0.00000000e+00  7.94241054e+01  7.57012594e-01  9.70739118e+00\n",
            "  2.46599486e+01  5.67692417e+00  4.22329011e-01  4.79757359e-01\n",
            "  4.67156151e-01  7.58990274e-01  2.87763952e-03  3.49015118e-02\n",
            "  1.59511409e-01  3.62293803e-01  5.40013375e-02  1.14497629e-03\n",
            "  1.59511409e-01  4.44639049e-01  4.41450790e-01  6.18534229e-01\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  2.07482867e+02  6.72297534e+01\n",
            "  9.03306921e-01  5.10910964e+00  2.05607649e+01  8.29205133e+02\n",
            "  4.01547238e-01  1.96475145e+05  7.66189180e+04  2.64631937e+05\n",
            "  1.43974902e+05  3.62997815e+06  4.33988291e+05  4.19536865e+06\n",
            "  3.25959760e+06  5.43925306e-04  2.39526786e+00]\n",
            "Standard deviation of X_train features: [5.77137624e-01 5.30914906e+00 1.09082929e+03 2.52784017e+03\n",
            " 2.38903410e+01 8.10952216e+02 3.29779474e+02 9.49987179e-01\n",
            " 1.93112096e+01 7.58583726e-01 9.36763165e-01 1.40404269e+00\n",
            " 3.77313627e+01 1.08597853e+00 9.91919628e-01 6.47958358e+03\n",
            " 1.62354912e+04 3.98146474e+02 2.16766966e+06 3.72640741e+03\n",
            " 7.63149433e+03 2.59156084e+04 1.55451097e+03 2.24222811e+06\n",
            " 6.43336921e+02 7.59110475e+02 8.51555305e+02 5.24391182e+02\n",
            " 3.24078311e+05 1.83530369e-01 0.00000000e+00 3.38181212e-02\n",
            " 0.00000000e+00 9.62943583e+02 1.56115554e+01 2.53960030e+01\n",
            " 6.09285431e+01 1.84469837e+01 6.89543766e-01 8.13090228e-01\n",
            " 7.21568521e-01 1.57947785e+00 5.35663954e-02 1.83530369e-01\n",
            " 3.66152317e-01 4.80663087e-01 2.26020338e-01 3.38181212e-02\n",
            " 3.66152317e-01 7.29019899e-01 7.58583725e-01 1.08597855e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 2.52784017e+03 8.10952216e+02\n",
            " 2.38903410e+01 3.29779474e+02 6.56097951e+01 1.01114579e+04\n",
            " 8.35637295e-01 1.78690604e+06 1.02778674e+06 2.36884322e+06\n",
            " 1.47073015e+06 1.44764118e+07 2.89102216e+06 1.57419513e+07\n",
            " 1.41568094e+07 5.77137624e-01 5.30914906e+00]\n",
            "Minimum value in X_train: -996114503.8969465\n",
            "Maximum value in X_train: 119516011.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Check for Missing Values\n",
        "missing_train = np.isnan(X_train).sum()\n",
        "missing_test = np.isnan(X_test).sum()\n",
        "print(f\"Missing values in X_train: {missing_train}\")\n",
        "print(f\"Missing values in X_test: {missing_test}\")\n",
        "\n",
        "# Check for Normalization (StandardScaler - assuming it was used)\n",
        "train_mean = np.mean(X_train, axis=0)\n",
        "train_std = np.std(X_train, axis=0)\n",
        "print(f\"Mean of X_train features: {train_mean}\")\n",
        "print(f\"Standard deviation of X_train features: {train_std}\")\n",
        "\n",
        "# Check for Normalization (MinMaxScaler - assuming it was used)\n",
        "train_min = np.min(X_train)\n",
        "train_max = np.max(X_train)\n",
        "print(f\"Minimum value in X_train: {train_min}\")\n",
        "print(f\"Maximum value in X_train: {train_max}\")"
      ],
      "metadata": {
        "outputId": "d6416a12-74aa-40bb-f0c4-d12b3c33bcfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWt5o-shkmat"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in X_train: 0\n",
            "Missing values in X_test: 0\n",
            "Mean of X_train features: [ 5.43925306e-04  2.39526786e+00  4.42044757e+00  2.07482867e+02\n",
            "  9.03306921e-01  6.72297534e+01  5.10910964e+00  5.18404426e-01\n",
            "  5.89625299e+00  4.41450787e-01  5.69658034e-01  8.17240972e-01\n",
            "  1.27670683e+01  6.18534215e-01  5.57835162e-01  1.13826988e-01\n",
            "  7.95485026e+01  4.54686345e+00 -3.12694287e+03  1.43741792e+01\n",
            "  9.18645846e+00  1.01414426e+02  1.69944173e+01 -1.03913065e+03\n",
            "  1.77238402e+02  1.45863457e+02  1.92735516e+02  1.27411851e+02\n",
            "  4.72145582e+04  3.49015118e-02  0.00000000e+00  1.14497629e-03\n",
            "  0.00000000e+00  7.94241054e+01  7.57012594e-01  9.70739118e+00\n",
            "  2.46599486e+01  5.67692417e+00  4.22329011e-01  4.79757359e-01\n",
            "  4.67156151e-01  7.58990274e-01  2.87763952e-03  3.49015118e-02\n",
            "  1.59511409e-01  3.62293803e-01  5.40013375e-02  1.14497629e-03\n",
            "  1.59511409e-01  4.44639049e-01  4.41450790e-01  6.18534229e-01\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  2.07482867e+02  6.72297534e+01\n",
            "  9.03306921e-01  5.10910964e+00  2.05607649e+01  8.29205133e+02\n",
            "  4.01547238e-01  1.96475145e+05  7.66189180e+04  2.64631937e+05\n",
            "  1.43974902e+05  3.62997815e+06  4.33988291e+05  4.19536865e+06\n",
            "  3.25959760e+06  5.43925306e-04  2.39526786e+00]\n",
            "Standard deviation of X_train features: [5.77137624e-01 5.30914906e+00 1.09082929e+03 2.52784017e+03\n",
            " 2.38903410e+01 8.10952216e+02 3.29779474e+02 9.49987179e-01\n",
            " 1.93112096e+01 7.58583726e-01 9.36763165e-01 1.40404269e+00\n",
            " 3.77313627e+01 1.08597853e+00 9.91919628e-01 6.47958358e+03\n",
            " 1.62354912e+04 3.98146474e+02 2.16766966e+06 3.72640741e+03\n",
            " 7.63149433e+03 2.59156084e+04 1.55451097e+03 2.24222811e+06\n",
            " 6.43336921e+02 7.59110475e+02 8.51555305e+02 5.24391182e+02\n",
            " 3.24078311e+05 1.83530369e-01 0.00000000e+00 3.38181212e-02\n",
            " 0.00000000e+00 9.62943583e+02 1.56115554e+01 2.53960030e+01\n",
            " 6.09285431e+01 1.84469837e+01 6.89543766e-01 8.13090228e-01\n",
            " 7.21568521e-01 1.57947785e+00 5.35663954e-02 1.83530369e-01\n",
            " 3.66152317e-01 4.80663087e-01 2.26020338e-01 3.38181212e-02\n",
            " 3.66152317e-01 7.29019899e-01 7.58583725e-01 1.08597855e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 2.52784017e+03 8.10952216e+02\n",
            " 2.38903410e+01 3.29779474e+02 6.56097951e+01 1.01114579e+04\n",
            " 8.35637295e-01 1.78690604e+06 1.02778674e+06 2.36884322e+06\n",
            " 1.47073015e+06 1.44764118e+07 2.89102216e+06 1.57419513e+07\n",
            " 1.41568094e+07 5.77137624e-01 5.30914906e+00]\n",
            "Minimum value in X_train: -996114503.8969465\n",
            "Maximum value in X_train: 119516011.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Assuming 'X_train' and 'X_test' are your training and testing data\n",
        "\n",
        "# 1. Apply RobustScaler\n",
        "scaler = RobustScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 2. (Optional) Log Transformation (if RobustScaler is not sufficient)\n",
        "# If the range is still too wide after RobustScaler, you can try log transformation:\n",
        "# for feature_index in features_with_wide_range:  # Replace with the indices of features with wide range\n",
        "#     X_train[:, feature_index] = np.log1p(X_train[:, feature_index])\n",
        "#     X_test[:, feature_index] = np.log1p(X_test[:, feature_index])"
      ],
      "metadata": {
        "id": "PW8VbTjpi36E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# ... (rest of your code)\n",
        "\n",
        "# 1. Force conversion of all object columns to numerical, replacing errors with NaN\n",
        "for col in X_train.select_dtypes(include=['object']).columns:\n",
        "    X_train[col] = pd.to_numeric(X_train[col], errors='coerce')\n",
        "    X_test[col] = pd.to_numeric(X_test[col], errors='coerce')\n",
        "\n",
        "# 2. Impute NaN values (using mean for example)\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].isnull().any():\n",
        "        X_train[col] = X_train[col].fillna(X_train[col].mean())\n",
        "        X_test[col] = X_test[col].fillna(X_train[col].mean())  # Use training mean for test\n",
        "\n",
        "# 3. Identify remaining categorical columns (after converting mixed types)\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "# 4. One-Hot Encoding (if any categorical features remain)\n",
        "if categorical_features.size > 0:\n",
        "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "    X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train[categorical_features]))\n",
        "    X_test_encoded = pd.DataFrame(encoder.transform(X_test[categorical_features]))\n",
        "\n",
        "    X_train_encoded.columns = encoder.get_feature_names_out(categorical_features)\n",
        "    X_test_encoded.columns = encoder.get_feature_names_out(categorical_features)\n",
        "\n",
        "    X_train = X_train.drop(categorical_features, axis=1)\n",
        "    X_test = X_test.drop(categorical_features, axis=1)\n",
        "    X_train = pd.concat([X_train, X_train_encoded], axis=1)\n",
        "    X_test = pd.concat([X_test, X_test_encoded], axis=1)\n",
        "\n",
        "# ... (Rest of your code for Label Encoding of target variable and model training)"
      ],
      "metadata": {
        "id": "VqjTPU2ZoH4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "# ... (Your existing code to load data, define feature_columns, target_column, etc.)\n",
        "\n",
        "# 1. Force conversion of all object columns to numerical, replacing errors with NaN\n",
        "# This is important because the RandomForestClassifier requires numerical input.\n",
        "for col in X_train.select_dtypes(include=['object']).columns:\n",
        "    X_train[col] = pd.to_numeric(X_train[col], errors='coerce')\n",
        "    X_test[col] = pd.to_numeric(X_test[col], errors='coerce')\n",
        "\n",
        "# 2. Impute NaN values (using mean for example)\n",
        "# We fill any missing values created during the conversion to numerical.\n",
        "# It's crucial to use the training data's mean for the test data to prevent data leakage.\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].isnull().any():\n",
        "        X_train[col] = X_train[col].fillna(X_train[col].mean())\n",
        "        X_test[col] = X_test[col].fillna(X_train[col].mean())\n",
        "\n",
        "# 3. Identify remaining categorical columns (after converting mixed types)\n",
        "# Even after conversion, some columns might still be categorical.\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "# 4. One-Hot Encoding (if any categorical features remain)\n",
        "# We use One-Hot Encoding to convert categorical features to numerical.\n",
        "# handle_unknown='ignore' is important to handle unseen categories in the test data.\n",
        "if categorical_features.size > 0:\n",
        "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "    X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train[categorical_features]))\n",
        "    X_test_encoded = pd.DataFrame(encoder.transform(X_test[categorical_features]))\n",
        "\n",
        "    X_train_encoded.columns = encoder.get_feature_names_out(categorical_features)\n",
        "    X_test_encoded.columns = encoder.get_feature_names_out(categorical_features)\n",
        "\n",
        "    X_train = X_train.drop(categorical_features, axis=1)\n",
        "    X_test = X_test.drop(categorical_features, axis=1)\n",
        "    X_train = pd.concat([X_train, X_train_encoded], axis=1)\n",
        "    X_test = pd.concat([X_test, X_test_encoded], axis=1)\n",
        "\n",
        "# 5. Label Encoding for the target variable\n",
        "# We convert the target variable to numerical labels using LabelEncoder.\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.transform(y_test)\n",
        "\n",
        "# 6. Create and train the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# 7. Make predictions on the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# 8. Evaluate the model and print the results\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted') # For multi-class\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "tWdHy5vfoIAW",
        "outputId": "10633bc0-7085-4c90-b1a8-0a53a966676c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9996757589267621\n",
            "Precision: 0.999675875258775\n",
            "Recall: 0.9996757589267621\n",
            "F1-score: 0.9996757800977603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8nLz_OvdoIDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GnvJWc6ioIGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mArzoKfroIJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tv8eorcFmXz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pxtwf-kpmX21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oVu5srbjmX6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IKnxGCklmX-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ18Kd5F3uKe"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib-venn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__3eqm3q3sr-"
      },
      "outputs": [],
      "source": [
        "!apt-get -qq install -y libfluidsynth1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apoRbfWsRZ7S"
      },
      "source": [
        "# Install 7zip reader [libarchive](https://pypi.python.org/pypi/libarchive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_j7nNbKRmhx"
      },
      "outputs": [],
      "source": [
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeaSX9KXR58J"
      },
      "source": [
        "# Install GraphViz & [PyDot](https://pypi.python.org/pypi/pydot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9llCG2wSRDx"
      },
      "outputs": [],
      "source": [
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tlh1MKxGrKFO"
      },
      "source": [
        "# Install [cartopy](http://scitools.org.uk/cartopy/docs/latest/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zq68DSY2rP2W"
      },
      "outputs": [],
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cL8xYwa042ZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2dEwazdm42hf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-IqrfYNV42ko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5ZjQvoA042o3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pgV7RZMB42sb"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}